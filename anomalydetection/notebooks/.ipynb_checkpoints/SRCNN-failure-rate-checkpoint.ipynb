{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d738256-a30f-4c6b-aa36-da51d083ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded. Total length: 3004067, number of anomalies: 79554\n"
     ]
    }
   ],
   "source": [
    "!python3 ../srcnn/srcnn_train/train.py --epochs=10 --lr=9.01143e-5 --momentum=0.66911 --batch-size=32 --window-steps=64 --data-path=../srcnn/srcnn_train --no-cuda --no-dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597619f1-9290-426a-a530-57db7cd65efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "import csv\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "Q = 3\n",
    "M = 5\n",
    "WINDOW_SIZE = 1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f075c495-2d29-467f-b042-0658ce603449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_kpi(csv_path):\n",
    "    kpis = {}\n",
    "    anomalies = 0\n",
    "    with open(csv_path) as f:\n",
    "        input = csv.reader(f, delimiter=',')\n",
    "        cnt = 0\n",
    "        for row in input:\n",
    "            if cnt == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "            kpi = kpis.get(str(row[3]), [[], [], []])\n",
    "            kpi[0].append(int(row[0]))  # timestamp\n",
    "            kpi[1].append(float(row[1]))  # value\n",
    "            kpi[2].append(int(row[2]))  # label\n",
    "            kpis[str(row[3])] = kpi\n",
    "            cnt += 1\n",
    "            if int(row[2]) == 1:\n",
    "                anomalies += 1\n",
    "        print(\"Training data loaded. Total length: {}, number of anomalies: {}\".format(cnt, anomalies))\n",
    "        f.close()\n",
    "    return kpis\n",
    "\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, window=WINDOW_SIZE):\n",
    "        self.window = window\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.layer1 = nn.Conv1d(window, window, kernel_size=1, stride=1, padding=0)\n",
    "        self.layer2 = nn.Conv1d(window, 2 * window, kernel_size=1, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(2 * window, 4 * window)\n",
    "        self.fc2 = nn.Linear(4 * window, window)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), self.window, 1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "def spectral_residual(values):\n",
    "    \"\"\"\n",
    "    This method transform a time series into spectral residual series\n",
    "    :param values: list.\n",
    "        a list of float values.\n",
    "    :return: mag: list.\n",
    "        a list of float values as the spectral residual values\n",
    "    \"\"\"\n",
    "    EPS = 1e-8\n",
    "    trans = np.fft.fft(values)\n",
    "    mag = np.sqrt(trans.real ** 2 + trans.imag ** 2)\n",
    "\n",
    "    maglog = [np.log(item) if abs(item) > EPS else 0 for item in mag]\n",
    "\n",
    "    spectral = np.exp(maglog - average_filter(maglog, n=Q))\n",
    "\n",
    "    trans.real = [ireal * ispectral / imag if abs(imag) > EPS else 0\n",
    "                  for ireal, ispectral, imag in zip(trans.real, spectral, mag)]\n",
    "    trans.imag = [iimag * ispectral / imag if abs(imag) > EPS else 0\n",
    "                  for iimag, ispectral, imag in zip(trans.imag, spectral, mag)]\n",
    "\n",
    "    wave_r = np.fft.ifft(trans)\n",
    "    mag = np.sqrt(wave_r.real ** 2 + wave_r.imag ** 2)\n",
    "\n",
    "    return mag\n",
    "\n",
    "\n",
    "def average_filter(values, n=3):\n",
    "    \"\"\"\n",
    "    Calculate the sliding window average for the give time series.\n",
    "    Mathematically, res[i] = sum_{j=i-t+1}^{i} values[j] / t, where t = min(n, i+1)\n",
    "    :param values: list.\n",
    "        a list of float numbers\n",
    "    :param n: int, default 3.\n",
    "        window size.\n",
    "    :return res: list.\n",
    "        a list of value after the average_filter process.\n",
    "    \"\"\"\n",
    "\n",
    "    if n >= len(values):\n",
    "        n = len(values)\n",
    "\n",
    "    res = np.cumsum(values, dtype=float)\n",
    "    res[n:] = res[n:] - res[:-n]\n",
    "    res[n:] = res[n:] / n\n",
    "\n",
    "    for i in range(1, n):\n",
    "        res[i] /= (i + 1)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def predict_next(values):\n",
    "    \"\"\"\n",
    "    Predicts the next value by sum up the slope of the last value with previous values.\n",
    "    Mathematically, g = 1/m * sum_{i=1}^{m} g(x_n, x_{n-i}), x_{n+1} = x_{n-m+1} + g * m,\n",
    "    where g(x_i,x_j) = (x_i - x_j) / (i - j)\n",
    "    :param values: list.\n",
    "        a list of float numbers.\n",
    "    :return : float.\n",
    "        the predicted next value.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(values) <= 1:\n",
    "        raise ValueError(f'data should contain at least 2 numbers')\n",
    "\n",
    "    v_last = values[-1]\n",
    "    n = len(values)\n",
    "\n",
    "    slopes = [(v_last - v) / (n - 1 - i) for i, v in enumerate(values[:-1])]\n",
    "\n",
    "    return values[1] + sum(slopes)\n",
    "\n",
    "\n",
    "def extend_series(values, extend_num=M, look_ahead=M):\n",
    "    \"\"\"\n",
    "    extend the array data by the predicted next value\n",
    "    :param values: list.\n",
    "        a list of float numbers.\n",
    "    :param extend_num: int, default 5.\n",
    "        number of values added to the back of data.\n",
    "    :param look_ahead: int, default 5.\n",
    "        number of previous values used in prediction.\n",
    "    :return: list.\n",
    "        The result array.\n",
    "    \"\"\"\n",
    "\n",
    "    if look_ahead < 1:\n",
    "        raise ValueError('look_ahead must be at least 1')\n",
    "\n",
    "    extension = [predict_next(values[-look_ahead - 2:-1])] * extend_num\n",
    "    return np.concatenate((values, extension), axis=0)\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    \"\"\"\n",
    "    to inject anomalous points according to the formula in the paper:\n",
    "    \"\"\"\n",
    "    def __init__(self, win_siz, step, nums):\n",
    "        self.control = 0\n",
    "        self.win_siz = win_siz\n",
    "        self.step = step\n",
    "        self.number = nums\n",
    "\n",
    "    def generate_train_data(self, value, back_k=0, insert_anomaly=True):\n",
    "        def normalize(a):\n",
    "            amin = np.min(a)\n",
    "            amax = np.max(a)\n",
    "            a = (a - amin) / (amax - amin + 1e-5)\n",
    "            return 3 * a\n",
    "\n",
    "        if back_k <= 5:\n",
    "            back = back_k\n",
    "        else:\n",
    "            back = 5\n",
    "        length = len(value)\n",
    "        tmp = []\n",
    "        for pt in range(self.win_siz, length - back, self.step):\n",
    "            head = max(0, pt - self.win_siz)\n",
    "            tail = min(length - back, pt)\n",
    "            data = np.array(value[head:tail])\n",
    "            data = data.astype(np.float64)\n",
    "            data = normalize(data)\n",
    "            num = np.random.randint(1, self.number)\n",
    "            ids = np.random.choice(self.win_siz, num, replace=False)\n",
    "            lbs = np.zeros(self.win_siz, dtype=np.int64)\n",
    "            if insert_anomaly:\n",
    "                if (self.win_siz - 6) not in ids:\n",
    "                    self.control += np.random.random()\n",
    "                else:\n",
    "                    self.control = 0\n",
    "                if self.control > 100:\n",
    "                    ids[0] = self.win_siz - 6\n",
    "                    self.control = 0\n",
    "                mean = np.mean(data)\n",
    "                dataavg = average_filter(data)\n",
    "                var = np.var(data)\n",
    "                for id in ids:\n",
    "                    data[id] += (dataavg[id] + mean) * np.random.randn() * min((1 + var), 10)\n",
    "                    lbs[id] = 1\n",
    "            tmp.append([data.tolist(), lbs.tolist()])\n",
    "        return tmp\n",
    "\n",
    "\n",
    "def cuda_if_available(x):\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x.cpu()\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, epoch, lr):\n",
    "    cur_lr = lr * (0.5 ** ((epoch + 10) // 10))\n",
    "    for param in optimizer.param_groups:\n",
    "        param['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def Var(x):\n",
    "    return Variable(cuda_if_available(x))\n",
    "\n",
    "\n",
    "def loss_function(x, lb, model, weight_decay, win_size=WINDOW_SIZE):\n",
    "    l2_reg = 0.\n",
    "    for W in model.parameters():\n",
    "        l2_reg = l2_reg + W.norm(2)\n",
    "    kpiweight = torch.ones(lb.shape)\n",
    "    kpiweight[lb == 1] = win_size // 100\n",
    "    kpiweight = cuda_if_available(kpiweight)\n",
    "    BCE = F.binary_cross_entropy(x, lb, weight=kpiweight, reduction='sum')\n",
    "    return l2_reg * weight_decay + BCE\n",
    "\n",
    "\n",
    "def calc(pred, true):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for pre, gt in zip(pred, true):\n",
    "        if gt == 1:\n",
    "            if pre == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        if gt == 0:\n",
    "            if pre == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    print('TP=%d FP=%d TN=%d FN=%d' % (TP, FP, TN, FN))\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "\n",
    "class SrDataset(Dataset):\n",
    "    '''\n",
    "    Dataset implementation for transforming data to spectral residual scores on the fly.\n",
    "    '''\n",
    "    def __init__(self, width, data):\n",
    "        self.genlen = 0\n",
    "        self.len = self.genlen\n",
    "        self.width = width\n",
    "        self.kpinegraw = data\n",
    "        self.negrawlen = len(self.kpinegraw)\n",
    "        print('length :', len(self.kpinegraw))\n",
    "        self.len += self.negrawlen\n",
    "        self.kpineglen = 0\n",
    "        self.control = 0.\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = index % self.negrawlen\n",
    "        datas = self.kpinegraw[idx]\n",
    "        datas = np.array(datas)\n",
    "        data = datas[0, :].astype(np.float64)\n",
    "        lbs = datas[1, :].astype(np.float64)\n",
    "        wave = spectral_residual(data)\n",
    "        waveavg = average_filter(wave)\n",
    "        for i in range(self.width):\n",
    "            if wave[i] < 0.001 and waveavg[i] < 0.001:\n",
    "                lbs[i] = 0\n",
    "                continue\n",
    "            ratio = wave[i] / waveavg[i]\n",
    "            if ratio < 1.0 and lbs[i] == 1:\n",
    "                lbs[i] = 0\n",
    "            if ratio > 5.0:\n",
    "                lbs[i] = 1\n",
    "        srscore = abs(wave - waveavg) / (waveavg + 0.01)\n",
    "        sortid = np.argsort(srscore)\n",
    "        for idx in sortid[-2:]:\n",
    "            if srscore[idx] > 3:\n",
    "                lbs[idx] = 1\n",
    "        resdata = torch.from_numpy(100 * wave)\n",
    "        reslb = torch.from_numpy(lbs)\n",
    "        return resdata, reslb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c5fa80-d212-4b21-980a-0372c96e0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded. Total length: 3004067, number of anomalies: 79554\n"
     ]
    }
   ],
   "source": [
    "kpis = load_kpi('../srcnn/srcnn_train/train.csv')\n",
    "training_data = []\n",
    "generator = DataGenerator(WINDOW_SIZE, 64, 10)\n",
    "for kpi in kpis.values():\n",
    "    in_value = kpi[1]\n",
    "    train_data = generator.generate_train_data(in_value)\n",
    "    training_data += train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec962f23-0a7f-4ed6-9de9-2a8137248277",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec8741b-b33c-4513-8c08-47d348461494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8bd743-c8e1-456b-b370-ea359688d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 46298\n"
     ]
    }
   ],
   "source": [
    "bp_parameters = filter(lambda p: p.requires_grad, model.parameters())  # back propagation parameters\n",
    "\n",
    "optimizer = optim.SGD(bp_parameters, lr=9.01143e-5, momentum=0.66911)\n",
    "\n",
    "training_dataset = SrDataset(WINDOW_SIZE, training_data)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, shuffle=True,\n",
    "                                               batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679448af-2d51-4c35-afa1-b402520fca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.float().to(device), target.float().to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target, model, 0.30) / len(data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        if batch_idx % 20 == 0:\n",
    "            msg = \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss={:.4f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item())\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c65fc3a-f6d9-43a4-8ef6-08049b5963e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/46298 (0%)]\tloss=1038.0557\n",
      "Train Epoch: 1 [640/46298 (1%)]\tloss=306.6516\n",
      "Train Epoch: 1 [1280/46298 (3%)]\tloss=327.8968\n",
      "Train Epoch: 1 [1920/46298 (4%)]\tloss=247.2234\n",
      "Train Epoch: 1 [2560/46298 (6%)]\tloss=306.9161\n",
      "Train Epoch: 1 [3200/46298 (7%)]\tloss=282.0711\n",
      "Train Epoch: 1 [3840/46298 (8%)]\tloss=268.9137\n",
      "Train Epoch: 1 [4480/46298 (10%)]\tloss=252.9304\n",
      "Train Epoch: 1 [5120/46298 (11%)]\tloss=288.9243\n",
      "Train Epoch: 1 [5760/46298 (12%)]\tloss=279.0595\n",
      "Train Epoch: 1 [6400/46298 (14%)]\tloss=323.3316\n",
      "Train Epoch: 1 [7040/46298 (15%)]\tloss=292.3781\n",
      "Train Epoch: 1 [7680/46298 (17%)]\tloss=280.2237\n",
      "Train Epoch: 1 [8320/46298 (18%)]\tloss=314.5863\n",
      "Train Epoch: 1 [8960/46298 (19%)]\tloss=274.2448\n",
      "Train Epoch: 1 [9600/46298 (21%)]\tloss=247.4700\n",
      "Train Epoch: 1 [10240/46298 (22%)]\tloss=275.3146\n",
      "Train Epoch: 1 [10880/46298 (23%)]\tloss=286.7146\n",
      "Train Epoch: 1 [11520/46298 (25%)]\tloss=261.3047\n",
      "Train Epoch: 1 [12160/46298 (26%)]\tloss=295.8310\n",
      "Train Epoch: 1 [12800/46298 (28%)]\tloss=271.5789\n",
      "Train Epoch: 1 [13440/46298 (29%)]\tloss=237.7239\n",
      "Train Epoch: 1 [14080/46298 (30%)]\tloss=261.0851\n",
      "Train Epoch: 1 [14720/46298 (32%)]\tloss=269.7861\n",
      "Train Epoch: 1 [15360/46298 (33%)]\tloss=300.3531\n",
      "Train Epoch: 1 [16000/46298 (35%)]\tloss=287.6477\n",
      "Train Epoch: 1 [16640/46298 (36%)]\tloss=280.4048\n",
      "Train Epoch: 1 [17280/46298 (37%)]\tloss=251.1342\n",
      "Train Epoch: 1 [17920/46298 (39%)]\tloss=268.4267\n",
      "Train Epoch: 1 [18560/46298 (40%)]\tloss=308.4862\n",
      "Train Epoch: 1 [19200/46298 (41%)]\tloss=271.5646\n",
      "Train Epoch: 1 [19840/46298 (43%)]\tloss=293.8098\n",
      "Train Epoch: 1 [20480/46298 (44%)]\tloss=284.9043\n",
      "Train Epoch: 1 [21120/46298 (46%)]\tloss=250.4114\n",
      "Train Epoch: 1 [21760/46298 (47%)]\tloss=227.2087\n",
      "Train Epoch: 1 [22400/46298 (48%)]\tloss=231.2567\n",
      "Train Epoch: 1 [23040/46298 (50%)]\tloss=280.9072\n",
      "Train Epoch: 1 [23680/46298 (51%)]\tloss=225.1757\n",
      "Train Epoch: 1 [24320/46298 (53%)]\tloss=267.6769\n",
      "Train Epoch: 1 [24960/46298 (54%)]\tloss=291.4007\n",
      "Train Epoch: 1 [25600/46298 (55%)]\tloss=257.6086\n",
      "Train Epoch: 1 [26240/46298 (57%)]\tloss=296.4099\n",
      "Train Epoch: 1 [26880/46298 (58%)]\tloss=273.3002\n",
      "Train Epoch: 1 [27520/46298 (59%)]\tloss=261.8256\n",
      "Train Epoch: 1 [28160/46298 (61%)]\tloss=257.6360\n",
      "Train Epoch: 1 [28800/46298 (62%)]\tloss=243.9000\n",
      "Train Epoch: 1 [29440/46298 (64%)]\tloss=247.4001\n",
      "Train Epoch: 1 [30080/46298 (65%)]\tloss=290.4789\n",
      "Train Epoch: 1 [30720/46298 (66%)]\tloss=268.5160\n",
      "Train Epoch: 1 [31360/46298 (68%)]\tloss=273.1463\n",
      "Train Epoch: 1 [32000/46298 (69%)]\tloss=261.9376\n",
      "Train Epoch: 1 [32640/46298 (70%)]\tloss=270.7808\n",
      "Train Epoch: 1 [33280/46298 (72%)]\tloss=263.1957\n",
      "Train Epoch: 1 [33920/46298 (73%)]\tloss=252.7357\n",
      "Train Epoch: 1 [34560/46298 (75%)]\tloss=270.3140\n",
      "Train Epoch: 1 [35200/46298 (76%)]\tloss=263.4686\n",
      "Train Epoch: 1 [35840/46298 (77%)]\tloss=261.5439\n",
      "Train Epoch: 1 [36480/46298 (79%)]\tloss=290.3262\n",
      "Train Epoch: 1 [37120/46298 (80%)]\tloss=247.8957\n",
      "Train Epoch: 1 [37760/46298 (82%)]\tloss=269.8442\n",
      "Train Epoch: 1 [38400/46298 (83%)]\tloss=291.2322\n",
      "Train Epoch: 1 [39040/46298 (84%)]\tloss=286.7212\n",
      "Train Epoch: 1 [39680/46298 (86%)]\tloss=248.9549\n",
      "Train Epoch: 1 [40320/46298 (87%)]\tloss=284.0485\n",
      "Train Epoch: 1 [40960/46298 (88%)]\tloss=243.2800\n",
      "Train Epoch: 1 [41600/46298 (90%)]\tloss=273.6043\n",
      "Train Epoch: 1 [42240/46298 (91%)]\tloss=255.8613\n",
      "Train Epoch: 1 [42880/46298 (93%)]\tloss=277.3972\n",
      "Train Epoch: 1 [43520/46298 (94%)]\tloss=228.3793\n",
      "Train Epoch: 1 [44160/46298 (95%)]\tloss=284.9576\n",
      "Train Epoch: 1 [44800/46298 (97%)]\tloss=267.3700\n",
      "Train Epoch: 1 [45440/46298 (98%)]\tloss=203.1859\n",
      "Train Epoch: 1 [46080/46298 (100%)]\tloss=266.9089\n",
      "Train Epoch: 2 [0/46298 (0%)]\tloss=227.6335\n",
      "Train Epoch: 2 [640/46298 (1%)]\tloss=238.3653\n",
      "Train Epoch: 2 [1280/46298 (3%)]\tloss=252.1184\n",
      "Train Epoch: 2 [1920/46298 (4%)]\tloss=229.6139\n",
      "Train Epoch: 2 [2560/46298 (6%)]\tloss=262.7725\n",
      "Train Epoch: 2 [3200/46298 (7%)]\tloss=261.6151\n",
      "Train Epoch: 2 [3840/46298 (8%)]\tloss=249.9616\n",
      "Train Epoch: 2 [4480/46298 (10%)]\tloss=297.3810\n",
      "Train Epoch: 2 [5120/46298 (11%)]\tloss=279.6074\n",
      "Train Epoch: 2 [5760/46298 (12%)]\tloss=253.8587\n",
      "Train Epoch: 2 [6400/46298 (14%)]\tloss=244.9286\n",
      "Train Epoch: 2 [7040/46298 (15%)]\tloss=229.7802\n",
      "Train Epoch: 2 [7680/46298 (17%)]\tloss=240.5579\n",
      "Train Epoch: 2 [8320/46298 (18%)]\tloss=204.7860\n",
      "Train Epoch: 2 [8960/46298 (19%)]\tloss=255.4564\n",
      "Train Epoch: 2 [9600/46298 (21%)]\tloss=236.7858\n",
      "Train Epoch: 2 [10240/46298 (22%)]\tloss=232.8993\n",
      "Train Epoch: 2 [10880/46298 (23%)]\tloss=270.7792\n",
      "Train Epoch: 2 [11520/46298 (25%)]\tloss=225.8766\n",
      "Train Epoch: 2 [12160/46298 (26%)]\tloss=231.0703\n",
      "Train Epoch: 2 [12800/46298 (28%)]\tloss=227.0855\n",
      "Train Epoch: 2 [13440/46298 (29%)]\tloss=235.7689\n",
      "Train Epoch: 2 [14080/46298 (30%)]\tloss=225.6153\n",
      "Train Epoch: 2 [14720/46298 (32%)]\tloss=216.6053\n",
      "Train Epoch: 2 [15360/46298 (33%)]\tloss=237.2104\n",
      "Train Epoch: 2 [16000/46298 (35%)]\tloss=214.3095\n",
      "Train Epoch: 2 [16640/46298 (36%)]\tloss=235.3878\n",
      "Train Epoch: 2 [17280/46298 (37%)]\tloss=237.6054\n",
      "Train Epoch: 2 [17920/46298 (39%)]\tloss=212.0519\n",
      "Train Epoch: 2 [18560/46298 (40%)]\tloss=236.5218\n",
      "Train Epoch: 2 [19200/46298 (41%)]\tloss=202.3317\n",
      "Train Epoch: 2 [19840/46298 (43%)]\tloss=228.0875\n",
      "Train Epoch: 2 [20480/46298 (44%)]\tloss=205.7014\n",
      "Train Epoch: 2 [21120/46298 (46%)]\tloss=215.7528\n",
      "Train Epoch: 2 [21760/46298 (47%)]\tloss=219.1388\n",
      "Train Epoch: 2 [22400/46298 (48%)]\tloss=201.0713\n",
      "Train Epoch: 2 [23040/46298 (50%)]\tloss=210.8452\n",
      "Train Epoch: 2 [23680/46298 (51%)]\tloss=242.9794\n",
      "Train Epoch: 2 [24320/46298 (53%)]\tloss=195.9817\n",
      "Train Epoch: 2 [24960/46298 (54%)]\tloss=207.0897\n",
      "Train Epoch: 2 [25600/46298 (55%)]\tloss=212.8085\n",
      "Train Epoch: 2 [26240/46298 (57%)]\tloss=203.7582\n",
      "Train Epoch: 2 [26880/46298 (58%)]\tloss=216.8130\n",
      "Train Epoch: 2 [27520/46298 (59%)]\tloss=204.3651\n",
      "Train Epoch: 2 [28160/46298 (61%)]\tloss=202.3559\n",
      "Train Epoch: 2 [28800/46298 (62%)]\tloss=232.7891\n",
      "Train Epoch: 2 [29440/46298 (64%)]\tloss=193.7264\n",
      "Train Epoch: 2 [30080/46298 (65%)]\tloss=208.8684\n",
      "Train Epoch: 2 [30720/46298 (66%)]\tloss=176.5655\n",
      "Train Epoch: 2 [31360/46298 (68%)]\tloss=200.9225\n",
      "Train Epoch: 2 [32000/46298 (69%)]\tloss=220.6270\n",
      "Train Epoch: 2 [32640/46298 (70%)]\tloss=207.2436\n",
      "Train Epoch: 2 [33280/46298 (72%)]\tloss=196.8773\n",
      "Train Epoch: 2 [33920/46298 (73%)]\tloss=191.7698\n",
      "Train Epoch: 2 [34560/46298 (75%)]\tloss=219.6763\n",
      "Train Epoch: 2 [35200/46298 (76%)]\tloss=176.8751\n",
      "Train Epoch: 2 [35840/46298 (77%)]\tloss=210.5896\n",
      "Train Epoch: 2 [36480/46298 (79%)]\tloss=202.0785\n",
      "Train Epoch: 2 [37120/46298 (80%)]\tloss=227.9012\n",
      "Train Epoch: 2 [37760/46298 (82%)]\tloss=227.9885\n",
      "Train Epoch: 2 [38400/46298 (83%)]\tloss=215.7670\n",
      "Train Epoch: 2 [39040/46298 (84%)]\tloss=239.3265\n",
      "Train Epoch: 2 [39680/46298 (86%)]\tloss=193.6740\n",
      "Train Epoch: 2 [40320/46298 (87%)]\tloss=203.0466\n",
      "Train Epoch: 2 [40960/46298 (88%)]\tloss=183.9859\n",
      "Train Epoch: 2 [41600/46298 (90%)]\tloss=187.8494\n",
      "Train Epoch: 2 [42240/46298 (91%)]\tloss=190.3181\n",
      "Train Epoch: 2 [42880/46298 (93%)]\tloss=191.8342\n",
      "Train Epoch: 2 [43520/46298 (94%)]\tloss=181.1503\n",
      "Train Epoch: 2 [44160/46298 (95%)]\tloss=166.7253\n",
      "Train Epoch: 2 [44800/46298 (97%)]\tloss=216.7939\n",
      "Train Epoch: 2 [45440/46298 (98%)]\tloss=237.2323\n",
      "Train Epoch: 2 [46080/46298 (100%)]\tloss=214.5375\n",
      "Train Epoch: 3 [0/46298 (0%)]\tloss=205.6184\n",
      "Train Epoch: 3 [640/46298 (1%)]\tloss=183.7063\n",
      "Train Epoch: 3 [1280/46298 (3%)]\tloss=200.6900\n",
      "Train Epoch: 3 [1920/46298 (4%)]\tloss=186.6246\n",
      "Train Epoch: 3 [2560/46298 (6%)]\tloss=186.2460\n",
      "Train Epoch: 3 [3200/46298 (7%)]\tloss=145.7796\n",
      "Train Epoch: 3 [3840/46298 (8%)]\tloss=148.8015\n",
      "Train Epoch: 3 [4480/46298 (10%)]\tloss=177.9039\n",
      "Train Epoch: 3 [5120/46298 (11%)]\tloss=183.1143\n",
      "Train Epoch: 3 [5760/46298 (12%)]\tloss=142.7541\n",
      "Train Epoch: 3 [6400/46298 (14%)]\tloss=185.2660\n",
      "Train Epoch: 3 [7040/46298 (15%)]\tloss=149.3831\n",
      "Train Epoch: 3 [7680/46298 (17%)]\tloss=171.9597\n",
      "Train Epoch: 3 [8320/46298 (18%)]\tloss=162.0920\n",
      "Train Epoch: 3 [8960/46298 (19%)]\tloss=188.5337\n",
      "Train Epoch: 3 [9600/46298 (21%)]\tloss=164.8854\n",
      "Train Epoch: 3 [10240/46298 (22%)]\tloss=163.6643\n",
      "Train Epoch: 3 [10880/46298 (23%)]\tloss=180.4384\n",
      "Train Epoch: 3 [11520/46298 (25%)]\tloss=178.6003\n",
      "Train Epoch: 3 [12160/46298 (26%)]\tloss=171.0669\n",
      "Train Epoch: 3 [12800/46298 (28%)]\tloss=201.7955\n",
      "Train Epoch: 3 [13440/46298 (29%)]\tloss=170.6884\n",
      "Train Epoch: 3 [14080/46298 (30%)]\tloss=191.6709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [14720/46298 (32%)]\tloss=187.0161\n",
      "Train Epoch: 3 [15360/46298 (33%)]\tloss=145.9764\n",
      "Train Epoch: 3 [16000/46298 (35%)]\tloss=195.2132\n",
      "Train Epoch: 3 [16640/46298 (36%)]\tloss=191.8328\n",
      "Train Epoch: 3 [17280/46298 (37%)]\tloss=158.4426\n",
      "Train Epoch: 3 [17920/46298 (39%)]\tloss=139.2911\n",
      "Train Epoch: 3 [18560/46298 (40%)]\tloss=172.2609\n",
      "Train Epoch: 3 [19200/46298 (41%)]\tloss=187.8621\n",
      "Train Epoch: 3 [19840/46298 (43%)]\tloss=176.5613\n",
      "Train Epoch: 3 [20480/46298 (44%)]\tloss=158.7863\n",
      "Train Epoch: 3 [21120/46298 (46%)]\tloss=154.9800\n",
      "Train Epoch: 3 [21760/46298 (47%)]\tloss=199.3573\n",
      "Train Epoch: 3 [22400/46298 (48%)]\tloss=156.7852\n",
      "Train Epoch: 3 [23040/46298 (50%)]\tloss=155.9472\n",
      "Train Epoch: 3 [23680/46298 (51%)]\tloss=155.0409\n",
      "Train Epoch: 3 [24320/46298 (53%)]\tloss=175.6373\n",
      "Train Epoch: 3 [24960/46298 (54%)]\tloss=157.0530\n",
      "Train Epoch: 3 [25600/46298 (55%)]\tloss=150.4164\n",
      "Train Epoch: 3 [26240/46298 (57%)]\tloss=132.3846\n",
      "Train Epoch: 3 [26880/46298 (58%)]\tloss=157.7999\n",
      "Train Epoch: 3 [27520/46298 (59%)]\tloss=190.9303\n",
      "Train Epoch: 3 [28160/46298 (61%)]\tloss=184.5897\n",
      "Train Epoch: 3 [28800/46298 (62%)]\tloss=134.2941\n",
      "Train Epoch: 3 [29440/46298 (64%)]\tloss=157.8533\n",
      "Train Epoch: 3 [30080/46298 (65%)]\tloss=146.5907\n",
      "Train Epoch: 3 [30720/46298 (66%)]\tloss=146.2970\n",
      "Train Epoch: 3 [31360/46298 (68%)]\tloss=184.3407\n",
      "Train Epoch: 3 [32000/46298 (69%)]\tloss=158.8276\n",
      "Train Epoch: 3 [32640/46298 (70%)]\tloss=158.3233\n",
      "Train Epoch: 3 [33280/46298 (72%)]\tloss=126.5199\n",
      "Train Epoch: 3 [33920/46298 (73%)]\tloss=141.8334\n",
      "Train Epoch: 3 [34560/46298 (75%)]\tloss=173.5468\n",
      "Train Epoch: 3 [35200/46298 (76%)]\tloss=145.3270\n",
      "Train Epoch: 3 [35840/46298 (77%)]\tloss=156.3556\n",
      "Train Epoch: 3 [36480/46298 (79%)]\tloss=170.3962\n",
      "Train Epoch: 3 [37120/46298 (80%)]\tloss=170.2847\n",
      "Train Epoch: 3 [37760/46298 (82%)]\tloss=166.1245\n",
      "Train Epoch: 3 [38400/46298 (83%)]\tloss=147.0588\n",
      "Train Epoch: 3 [39040/46298 (84%)]\tloss=172.4591\n",
      "Train Epoch: 3 [39680/46298 (86%)]\tloss=143.4648\n",
      "Train Epoch: 3 [40320/46298 (87%)]\tloss=127.5545\n",
      "Train Epoch: 3 [40960/46298 (88%)]\tloss=149.2142\n",
      "Train Epoch: 3 [41600/46298 (90%)]\tloss=142.1444\n",
      "Train Epoch: 3 [42240/46298 (91%)]\tloss=147.5915\n",
      "Train Epoch: 3 [42880/46298 (93%)]\tloss=171.0979\n",
      "Train Epoch: 3 [43520/46298 (94%)]\tloss=194.3193\n",
      "Train Epoch: 3 [44160/46298 (95%)]\tloss=169.0305\n",
      "Train Epoch: 3 [44800/46298 (97%)]\tloss=151.1598\n",
      "Train Epoch: 3 [45440/46298 (98%)]\tloss=158.7868\n",
      "Train Epoch: 3 [46080/46298 (100%)]\tloss=146.6893\n",
      "Train Epoch: 4 [0/46298 (0%)]\tloss=162.5792\n",
      "Train Epoch: 4 [640/46298 (1%)]\tloss=150.1751\n",
      "Train Epoch: 4 [1280/46298 (3%)]\tloss=116.3517\n",
      "Train Epoch: 4 [1920/46298 (4%)]\tloss=161.5219\n",
      "Train Epoch: 4 [2560/46298 (6%)]\tloss=132.1112\n",
      "Train Epoch: 4 [3200/46298 (7%)]\tloss=134.5059\n",
      "Train Epoch: 4 [3840/46298 (8%)]\tloss=145.9055\n",
      "Train Epoch: 4 [4480/46298 (10%)]\tloss=141.7567\n",
      "Train Epoch: 4 [5120/46298 (11%)]\tloss=137.3223\n",
      "Train Epoch: 4 [5760/46298 (12%)]\tloss=146.5359\n",
      "Train Epoch: 4 [6400/46298 (14%)]\tloss=133.4227\n",
      "Train Epoch: 4 [7040/46298 (15%)]\tloss=120.7230\n",
      "Train Epoch: 4 [7680/46298 (17%)]\tloss=129.8940\n",
      "Train Epoch: 4 [8320/46298 (18%)]\tloss=129.9187\n",
      "Train Epoch: 4 [8960/46298 (19%)]\tloss=121.0716\n",
      "Train Epoch: 4 [9600/46298 (21%)]\tloss=129.2326\n",
      "Train Epoch: 4 [10240/46298 (22%)]\tloss=154.6883\n",
      "Train Epoch: 4 [10880/46298 (23%)]\tloss=160.2823\n",
      "Train Epoch: 4 [11520/46298 (25%)]\tloss=121.5343\n",
      "Train Epoch: 4 [12160/46298 (26%)]\tloss=132.8591\n",
      "Train Epoch: 4 [12800/46298 (28%)]\tloss=128.9941\n",
      "Train Epoch: 4 [13440/46298 (29%)]\tloss=141.6283\n",
      "Train Epoch: 4 [14080/46298 (30%)]\tloss=129.5734\n",
      "Train Epoch: 4 [14720/46298 (32%)]\tloss=124.7314\n",
      "Train Epoch: 4 [15360/46298 (33%)]\tloss=107.5594\n",
      "Train Epoch: 4 [16000/46298 (35%)]\tloss=137.0869\n",
      "Train Epoch: 4 [16640/46298 (36%)]\tloss=118.0358\n",
      "Train Epoch: 4 [17280/46298 (37%)]\tloss=101.8306\n",
      "Train Epoch: 4 [17920/46298 (39%)]\tloss=137.1974\n",
      "Train Epoch: 4 [18560/46298 (40%)]\tloss=134.2052\n",
      "Train Epoch: 4 [19200/46298 (41%)]\tloss=159.1736\n",
      "Train Epoch: 4 [19840/46298 (43%)]\tloss=127.1892\n",
      "Train Epoch: 4 [20480/46298 (44%)]\tloss=121.3184\n",
      "Train Epoch: 4 [21120/46298 (46%)]\tloss=118.1086\n",
      "Train Epoch: 4 [21760/46298 (47%)]\tloss=111.7803\n",
      "Train Epoch: 4 [22400/46298 (48%)]\tloss=115.6067\n",
      "Train Epoch: 4 [23040/46298 (50%)]\tloss=122.9223\n",
      "Train Epoch: 4 [23680/46298 (51%)]\tloss=151.7507\n",
      "Train Epoch: 4 [24320/46298 (53%)]\tloss=154.7505\n",
      "Train Epoch: 4 [24960/46298 (54%)]\tloss=111.2564\n",
      "Train Epoch: 4 [25600/46298 (55%)]\tloss=123.2676\n",
      "Train Epoch: 4 [26240/46298 (57%)]\tloss=135.7313\n",
      "Train Epoch: 4 [26880/46298 (58%)]\tloss=160.2186\n",
      "Train Epoch: 4 [27520/46298 (59%)]\tloss=147.0975\n",
      "Train Epoch: 4 [28160/46298 (61%)]\tloss=146.8091\n",
      "Train Epoch: 4 [28800/46298 (62%)]\tloss=132.1164\n",
      "Train Epoch: 4 [29440/46298 (64%)]\tloss=124.0243\n",
      "Train Epoch: 4 [30080/46298 (65%)]\tloss=103.9817\n",
      "Train Epoch: 4 [30720/46298 (66%)]\tloss=138.9758\n",
      "Train Epoch: 4 [31360/46298 (68%)]\tloss=124.8437\n",
      "Train Epoch: 4 [32000/46298 (69%)]\tloss=129.6472\n",
      "Train Epoch: 4 [32640/46298 (70%)]\tloss=155.7080\n",
      "Train Epoch: 4 [33280/46298 (72%)]\tloss=145.5594\n",
      "Train Epoch: 4 [33920/46298 (73%)]\tloss=111.9346\n",
      "Train Epoch: 4 [34560/46298 (75%)]\tloss=144.8822\n",
      "Train Epoch: 4 [35200/46298 (76%)]\tloss=118.5264\n",
      "Train Epoch: 4 [35840/46298 (77%)]\tloss=158.1769\n",
      "Train Epoch: 4 [36480/46298 (79%)]\tloss=165.5748\n",
      "Train Epoch: 4 [37120/46298 (80%)]\tloss=121.0226\n",
      "Train Epoch: 4 [37760/46298 (82%)]\tloss=153.6940\n",
      "Train Epoch: 4 [38400/46298 (83%)]\tloss=144.7612\n",
      "Train Epoch: 4 [39040/46298 (84%)]\tloss=153.3870\n",
      "Train Epoch: 4 [39680/46298 (86%)]\tloss=115.9883\n",
      "Train Epoch: 4 [40320/46298 (87%)]\tloss=125.6999\n",
      "Train Epoch: 4 [40960/46298 (88%)]\tloss=140.8122\n",
      "Train Epoch: 4 [41600/46298 (90%)]\tloss=118.0590\n",
      "Train Epoch: 4 [42240/46298 (91%)]\tloss=147.7193\n",
      "Train Epoch: 4 [42880/46298 (93%)]\tloss=109.0236\n",
      "Train Epoch: 4 [43520/46298 (94%)]\tloss=106.1605\n",
      "Train Epoch: 4 [44160/46298 (95%)]\tloss=110.5733\n",
      "Train Epoch: 4 [44800/46298 (97%)]\tloss=116.5191\n",
      "Train Epoch: 4 [45440/46298 (98%)]\tloss=120.1059\n",
      "Train Epoch: 4 [46080/46298 (100%)]\tloss=128.5641\n",
      "Train Epoch: 5 [0/46298 (0%)]\tloss=89.7988\n",
      "Train Epoch: 5 [640/46298 (1%)]\tloss=119.4567\n",
      "Train Epoch: 5 [1280/46298 (3%)]\tloss=97.8021\n",
      "Train Epoch: 5 [1920/46298 (4%)]\tloss=100.8166\n",
      "Train Epoch: 5 [2560/46298 (6%)]\tloss=109.2116\n",
      "Train Epoch: 5 [3200/46298 (7%)]\tloss=104.2391\n",
      "Train Epoch: 5 [3840/46298 (8%)]\tloss=128.4967\n",
      "Train Epoch: 5 [4480/46298 (10%)]\tloss=110.5891\n",
      "Train Epoch: 5 [5120/46298 (11%)]\tloss=118.7099\n",
      "Train Epoch: 5 [5760/46298 (12%)]\tloss=107.3644\n",
      "Train Epoch: 5 [6400/46298 (14%)]\tloss=92.2908\n",
      "Train Epoch: 5 [7040/46298 (15%)]\tloss=116.5388\n",
      "Train Epoch: 5 [7680/46298 (17%)]\tloss=120.0979\n",
      "Train Epoch: 5 [8320/46298 (18%)]\tloss=116.6710\n",
      "Train Epoch: 5 [8960/46298 (19%)]\tloss=99.3224\n",
      "Train Epoch: 5 [9600/46298 (21%)]\tloss=103.2259\n",
      "Train Epoch: 5 [10240/46298 (22%)]\tloss=90.5420\n",
      "Train Epoch: 5 [10880/46298 (23%)]\tloss=110.0754\n",
      "Train Epoch: 5 [11520/46298 (25%)]\tloss=98.4497\n",
      "Train Epoch: 5 [12160/46298 (26%)]\tloss=115.0362\n",
      "Train Epoch: 5 [12800/46298 (28%)]\tloss=135.2356\n",
      "Train Epoch: 5 [13440/46298 (29%)]\tloss=102.1170\n",
      "Train Epoch: 5 [14080/46298 (30%)]\tloss=99.8104\n",
      "Train Epoch: 5 [14720/46298 (32%)]\tloss=91.2865\n",
      "Train Epoch: 5 [15360/46298 (33%)]\tloss=93.4858\n",
      "Train Epoch: 5 [16000/46298 (35%)]\tloss=131.8047\n",
      "Train Epoch: 5 [16640/46298 (36%)]\tloss=102.4547\n",
      "Train Epoch: 5 [17280/46298 (37%)]\tloss=127.2838\n",
      "Train Epoch: 5 [17920/46298 (39%)]\tloss=138.0871\n",
      "Train Epoch: 5 [18560/46298 (40%)]\tloss=90.6382\n",
      "Train Epoch: 5 [19200/46298 (41%)]\tloss=113.0233\n",
      "Train Epoch: 5 [19840/46298 (43%)]\tloss=116.4962\n",
      "Train Epoch: 5 [20480/46298 (44%)]\tloss=96.1063\n",
      "Train Epoch: 5 [21120/46298 (46%)]\tloss=90.5143\n",
      "Train Epoch: 5 [21760/46298 (47%)]\tloss=104.2510\n",
      "Train Epoch: 5 [22400/46298 (48%)]\tloss=93.9074\n",
      "Train Epoch: 5 [23040/46298 (50%)]\tloss=103.6917\n",
      "Train Epoch: 5 [23680/46298 (51%)]\tloss=123.6685\n",
      "Train Epoch: 5 [24320/46298 (53%)]\tloss=99.1008\n",
      "Train Epoch: 5 [24960/46298 (54%)]\tloss=115.0609\n",
      "Train Epoch: 5 [25600/46298 (55%)]\tloss=133.4071\n",
      "Train Epoch: 5 [26240/46298 (57%)]\tloss=148.3869\n",
      "Train Epoch: 5 [26880/46298 (58%)]\tloss=106.6910\n",
      "Train Epoch: 5 [27520/46298 (59%)]\tloss=135.7906\n",
      "Train Epoch: 5 [28160/46298 (61%)]\tloss=109.3638\n",
      "Train Epoch: 5 [28800/46298 (62%)]\tloss=94.5019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [29440/46298 (64%)]\tloss=103.4030\n",
      "Train Epoch: 5 [30080/46298 (65%)]\tloss=101.0678\n",
      "Train Epoch: 5 [30720/46298 (66%)]\tloss=111.1209\n",
      "Train Epoch: 5 [31360/46298 (68%)]\tloss=117.4951\n",
      "Train Epoch: 5 [32000/46298 (69%)]\tloss=88.9512\n",
      "Train Epoch: 5 [32640/46298 (70%)]\tloss=121.9174\n",
      "Train Epoch: 5 [33280/46298 (72%)]\tloss=108.0537\n",
      "Train Epoch: 5 [33920/46298 (73%)]\tloss=104.4594\n",
      "Train Epoch: 5 [34560/46298 (75%)]\tloss=95.5495\n",
      "Train Epoch: 5 [35200/46298 (76%)]\tloss=103.9511\n",
      "Train Epoch: 5 [35840/46298 (77%)]\tloss=112.7974\n",
      "Train Epoch: 5 [36480/46298 (79%)]\tloss=127.7305\n",
      "Train Epoch: 5 [37120/46298 (80%)]\tloss=91.0611\n",
      "Train Epoch: 5 [37760/46298 (82%)]\tloss=127.8748\n",
      "Train Epoch: 5 [38400/46298 (83%)]\tloss=93.3989\n",
      "Train Epoch: 5 [39040/46298 (84%)]\tloss=96.6569\n",
      "Train Epoch: 5 [39680/46298 (86%)]\tloss=118.9585\n",
      "Train Epoch: 5 [40320/46298 (87%)]\tloss=108.9900\n",
      "Train Epoch: 5 [40960/46298 (88%)]\tloss=92.5786\n",
      "Train Epoch: 5 [41600/46298 (90%)]\tloss=103.4051\n",
      "Train Epoch: 5 [42240/46298 (91%)]\tloss=107.4828\n",
      "Train Epoch: 5 [42880/46298 (93%)]\tloss=112.5488\n",
      "Train Epoch: 5 [43520/46298 (94%)]\tloss=122.8263\n",
      "Train Epoch: 5 [44160/46298 (95%)]\tloss=99.4668\n",
      "Train Epoch: 5 [44800/46298 (97%)]\tloss=96.8860\n",
      "Train Epoch: 5 [45440/46298 (98%)]\tloss=131.3829\n",
      "Train Epoch: 5 [46080/46298 (100%)]\tloss=108.3613\n",
      "Train Epoch: 6 [0/46298 (0%)]\tloss=96.7615\n",
      "Train Epoch: 6 [640/46298 (1%)]\tloss=105.0677\n",
      "Train Epoch: 6 [1280/46298 (3%)]\tloss=83.4850\n",
      "Train Epoch: 6 [1920/46298 (4%)]\tloss=107.4266\n",
      "Train Epoch: 6 [2560/46298 (6%)]\tloss=104.5033\n",
      "Train Epoch: 6 [3200/46298 (7%)]\tloss=86.9058\n",
      "Train Epoch: 6 [3840/46298 (8%)]\tloss=88.4298\n",
      "Train Epoch: 6 [4480/46298 (10%)]\tloss=101.9621\n",
      "Train Epoch: 6 [5120/46298 (11%)]\tloss=79.8960\n",
      "Train Epoch: 6 [5760/46298 (12%)]\tloss=86.8439\n",
      "Train Epoch: 6 [6400/46298 (14%)]\tloss=85.9811\n",
      "Train Epoch: 6 [7040/46298 (15%)]\tloss=94.8426\n",
      "Train Epoch: 6 [7680/46298 (17%)]\tloss=105.6490\n",
      "Train Epoch: 6 [8320/46298 (18%)]\tloss=80.5700\n",
      "Train Epoch: 6 [8960/46298 (19%)]\tloss=82.8092\n",
      "Train Epoch: 6 [9600/46298 (21%)]\tloss=92.9826\n",
      "Train Epoch: 6 [10240/46298 (22%)]\tloss=107.7054\n",
      "Train Epoch: 6 [10880/46298 (23%)]\tloss=119.3098\n",
      "Train Epoch: 6 [11520/46298 (25%)]\tloss=81.9286\n",
      "Train Epoch: 6 [12160/46298 (26%)]\tloss=117.3608\n",
      "Train Epoch: 6 [12800/46298 (28%)]\tloss=78.5798\n",
      "Train Epoch: 6 [13440/46298 (29%)]\tloss=103.5754\n",
      "Train Epoch: 6 [14080/46298 (30%)]\tloss=78.1340\n",
      "Train Epoch: 6 [14720/46298 (32%)]\tloss=88.0436\n",
      "Train Epoch: 6 [15360/46298 (33%)]\tloss=91.0126\n",
      "Train Epoch: 6 [16000/46298 (35%)]\tloss=104.7485\n",
      "Train Epoch: 6 [16640/46298 (36%)]\tloss=95.9140\n",
      "Train Epoch: 6 [17280/46298 (37%)]\tloss=103.6215\n",
      "Train Epoch: 6 [17920/46298 (39%)]\tloss=85.6198\n",
      "Train Epoch: 6 [18560/46298 (40%)]\tloss=120.0118\n",
      "Train Epoch: 6 [19200/46298 (41%)]\tloss=90.6574\n",
      "Train Epoch: 6 [19840/46298 (43%)]\tloss=123.0659\n",
      "Train Epoch: 6 [20480/46298 (44%)]\tloss=90.1336\n",
      "Train Epoch: 6 [21120/46298 (46%)]\tloss=115.9177\n",
      "Train Epoch: 6 [21760/46298 (47%)]\tloss=96.6194\n",
      "Train Epoch: 6 [22400/46298 (48%)]\tloss=89.2974\n",
      "Train Epoch: 6 [23040/46298 (50%)]\tloss=87.2972\n",
      "Train Epoch: 6 [23680/46298 (51%)]\tloss=75.3384\n",
      "Train Epoch: 6 [24320/46298 (53%)]\tloss=112.1422\n",
      "Train Epoch: 6 [24960/46298 (54%)]\tloss=75.3148\n",
      "Train Epoch: 6 [25600/46298 (55%)]\tloss=119.2410\n",
      "Train Epoch: 6 [26240/46298 (57%)]\tloss=103.7581\n",
      "Train Epoch: 6 [26880/46298 (58%)]\tloss=96.9726\n",
      "Train Epoch: 6 [27520/46298 (59%)]\tloss=92.9497\n",
      "Train Epoch: 6 [28160/46298 (61%)]\tloss=77.1348\n",
      "Train Epoch: 6 [28800/46298 (62%)]\tloss=93.9865\n",
      "Train Epoch: 6 [29440/46298 (64%)]\tloss=99.7204\n",
      "Train Epoch: 6 [30080/46298 (65%)]\tloss=100.2414\n",
      "Train Epoch: 6 [30720/46298 (66%)]\tloss=75.3654\n",
      "Train Epoch: 6 [31360/46298 (68%)]\tloss=120.3984\n",
      "Train Epoch: 6 [32000/46298 (69%)]\tloss=105.1770\n",
      "Train Epoch: 6 [32640/46298 (70%)]\tloss=105.4024\n",
      "Train Epoch: 6 [33280/46298 (72%)]\tloss=93.7133\n",
      "Train Epoch: 6 [33920/46298 (73%)]\tloss=103.6749\n",
      "Train Epoch: 6 [34560/46298 (75%)]\tloss=92.4871\n",
      "Train Epoch: 6 [35200/46298 (76%)]\tloss=92.7914\n",
      "Train Epoch: 6 [35840/46298 (77%)]\tloss=92.2865\n",
      "Train Epoch: 6 [36480/46298 (79%)]\tloss=97.3996\n",
      "Train Epoch: 6 [37120/46298 (80%)]\tloss=91.6587\n",
      "Train Epoch: 6 [37760/46298 (82%)]\tloss=95.4854\n",
      "Train Epoch: 6 [38400/46298 (83%)]\tloss=101.6199\n",
      "Train Epoch: 6 [39040/46298 (84%)]\tloss=103.7569\n",
      "Train Epoch: 6 [39680/46298 (86%)]\tloss=97.2773\n",
      "Train Epoch: 6 [40320/46298 (87%)]\tloss=107.4118\n",
      "Train Epoch: 6 [40960/46298 (88%)]\tloss=82.1886\n",
      "Train Epoch: 6 [41600/46298 (90%)]\tloss=112.1818\n",
      "Train Epoch: 6 [42240/46298 (91%)]\tloss=116.3182\n",
      "Train Epoch: 6 [42880/46298 (93%)]\tloss=93.5619\n",
      "Train Epoch: 6 [43520/46298 (94%)]\tloss=92.7985\n",
      "Train Epoch: 6 [44160/46298 (95%)]\tloss=100.9588\n",
      "Train Epoch: 6 [44800/46298 (97%)]\tloss=87.3549\n",
      "Train Epoch: 6 [45440/46298 (98%)]\tloss=90.7491\n",
      "Train Epoch: 6 [46080/46298 (100%)]\tloss=99.4532\n",
      "Train Epoch: 7 [0/46298 (0%)]\tloss=86.4666\n",
      "Train Epoch: 7 [640/46298 (1%)]\tloss=71.7807\n",
      "Train Epoch: 7 [1280/46298 (3%)]\tloss=119.5801\n",
      "Train Epoch: 7 [1920/46298 (4%)]\tloss=65.5435\n",
      "Train Epoch: 7 [2560/46298 (6%)]\tloss=68.7204\n",
      "Train Epoch: 7 [3200/46298 (7%)]\tloss=94.8841\n",
      "Train Epoch: 7 [3840/46298 (8%)]\tloss=76.2903\n",
      "Train Epoch: 7 [4480/46298 (10%)]\tloss=114.0577\n",
      "Train Epoch: 7 [5120/46298 (11%)]\tloss=73.7804\n",
      "Train Epoch: 7 [5760/46298 (12%)]\tloss=84.0773\n",
      "Train Epoch: 7 [6400/46298 (14%)]\tloss=70.4297\n",
      "Train Epoch: 7 [7040/46298 (15%)]\tloss=87.4226\n",
      "Train Epoch: 7 [7680/46298 (17%)]\tloss=77.0133\n",
      "Train Epoch: 7 [8320/46298 (18%)]\tloss=75.3050\n",
      "Train Epoch: 7 [8960/46298 (19%)]\tloss=81.3395\n",
      "Train Epoch: 7 [9600/46298 (21%)]\tloss=83.5353\n",
      "Train Epoch: 7 [10240/46298 (22%)]\tloss=93.9425\n",
      "Train Epoch: 7 [10880/46298 (23%)]\tloss=63.9506\n",
      "Train Epoch: 7 [11520/46298 (25%)]\tloss=81.6620\n",
      "Train Epoch: 7 [12160/46298 (26%)]\tloss=76.3634\n",
      "Train Epoch: 7 [12800/46298 (28%)]\tloss=59.7577\n",
      "Train Epoch: 7 [13440/46298 (29%)]\tloss=93.5377\n",
      "Train Epoch: 7 [14080/46298 (30%)]\tloss=77.0437\n",
      "Train Epoch: 7 [14720/46298 (32%)]\tloss=71.4543\n",
      "Train Epoch: 7 [15360/46298 (33%)]\tloss=80.9887\n",
      "Train Epoch: 7 [16000/46298 (35%)]\tloss=100.0167\n",
      "Train Epoch: 7 [16640/46298 (36%)]\tloss=77.9034\n",
      "Train Epoch: 7 [17280/46298 (37%)]\tloss=88.1259\n",
      "Train Epoch: 7 [17920/46298 (39%)]\tloss=73.6675\n",
      "Train Epoch: 7 [18560/46298 (40%)]\tloss=83.1151\n",
      "Train Epoch: 7 [19200/46298 (41%)]\tloss=85.1797\n",
      "Train Epoch: 7 [19840/46298 (43%)]\tloss=83.8840\n",
      "Train Epoch: 7 [20480/46298 (44%)]\tloss=76.3942\n",
      "Train Epoch: 7 [21120/46298 (46%)]\tloss=89.1742\n",
      "Train Epoch: 7 [21760/46298 (47%)]\tloss=74.3664\n",
      "Train Epoch: 7 [22400/46298 (48%)]\tloss=62.5531\n",
      "Train Epoch: 7 [23040/46298 (50%)]\tloss=73.4540\n",
      "Train Epoch: 7 [23680/46298 (51%)]\tloss=72.2883\n",
      "Train Epoch: 7 [24320/46298 (53%)]\tloss=92.5500\n",
      "Train Epoch: 7 [24960/46298 (54%)]\tloss=84.5457\n",
      "Train Epoch: 7 [25600/46298 (55%)]\tloss=73.3700\n",
      "Train Epoch: 7 [26240/46298 (57%)]\tloss=73.4991\n",
      "Train Epoch: 7 [26880/46298 (58%)]\tloss=85.6800\n",
      "Train Epoch: 7 [27520/46298 (59%)]\tloss=71.8653\n",
      "Train Epoch: 7 [28160/46298 (61%)]\tloss=58.5215\n",
      "Train Epoch: 7 [28800/46298 (62%)]\tloss=90.1555\n",
      "Train Epoch: 7 [29440/46298 (64%)]\tloss=74.3033\n",
      "Train Epoch: 7 [30080/46298 (65%)]\tloss=77.2431\n",
      "Train Epoch: 7 [30720/46298 (66%)]\tloss=68.5283\n",
      "Train Epoch: 7 [31360/46298 (68%)]\tloss=82.1353\n",
      "Train Epoch: 7 [32000/46298 (69%)]\tloss=95.6363\n",
      "Train Epoch: 7 [32640/46298 (70%)]\tloss=72.3803\n",
      "Train Epoch: 7 [33280/46298 (72%)]\tloss=69.1428\n",
      "Train Epoch: 7 [33920/46298 (73%)]\tloss=81.5220\n",
      "Train Epoch: 7 [34560/46298 (75%)]\tloss=79.8399\n",
      "Train Epoch: 7 [35200/46298 (76%)]\tloss=85.3939\n",
      "Train Epoch: 7 [35840/46298 (77%)]\tloss=87.5538\n",
      "Train Epoch: 7 [36480/46298 (79%)]\tloss=88.7587\n",
      "Train Epoch: 7 [37120/46298 (80%)]\tloss=106.6116\n",
      "Train Epoch: 7 [37760/46298 (82%)]\tloss=98.7591\n",
      "Train Epoch: 7 [38400/46298 (83%)]\tloss=90.1196\n",
      "Train Epoch: 7 [39040/46298 (84%)]\tloss=86.8596\n",
      "Train Epoch: 7 [39680/46298 (86%)]\tloss=82.8770\n",
      "Train Epoch: 7 [40320/46298 (87%)]\tloss=82.8437\n",
      "Train Epoch: 7 [40960/46298 (88%)]\tloss=94.5669\n",
      "Train Epoch: 7 [41600/46298 (90%)]\tloss=95.2005\n",
      "Train Epoch: 7 [42240/46298 (91%)]\tloss=64.8860\n",
      "Train Epoch: 7 [42880/46298 (93%)]\tloss=70.2768\n",
      "Train Epoch: 7 [43520/46298 (94%)]\tloss=62.1865\n",
      "Train Epoch: 7 [44160/46298 (95%)]\tloss=92.6593\n",
      "Train Epoch: 7 [44800/46298 (97%)]\tloss=62.8648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [45440/46298 (98%)]\tloss=76.2066\n",
      "Train Epoch: 7 [46080/46298 (100%)]\tloss=87.1264\n",
      "Train Epoch: 8 [0/46298 (0%)]\tloss=55.3634\n",
      "Train Epoch: 8 [640/46298 (1%)]\tloss=61.6727\n",
      "Train Epoch: 8 [1280/46298 (3%)]\tloss=71.0926\n",
      "Train Epoch: 8 [1920/46298 (4%)]\tloss=67.7176\n",
      "Train Epoch: 8 [2560/46298 (6%)]\tloss=73.3069\n",
      "Train Epoch: 8 [3200/46298 (7%)]\tloss=60.5608\n",
      "Train Epoch: 8 [3840/46298 (8%)]\tloss=71.3783\n",
      "Train Epoch: 8 [4480/46298 (10%)]\tloss=81.1556\n",
      "Train Epoch: 8 [5120/46298 (11%)]\tloss=65.1582\n",
      "Train Epoch: 8 [5760/46298 (12%)]\tloss=63.0211\n",
      "Train Epoch: 8 [6400/46298 (14%)]\tloss=68.7305\n",
      "Train Epoch: 8 [7040/46298 (15%)]\tloss=55.2773\n",
      "Train Epoch: 8 [7680/46298 (17%)]\tloss=65.4564\n",
      "Train Epoch: 8 [8320/46298 (18%)]\tloss=62.9725\n",
      "Train Epoch: 8 [8960/46298 (19%)]\tloss=73.1797\n",
      "Train Epoch: 8 [9600/46298 (21%)]\tloss=89.3960\n",
      "Train Epoch: 8 [10240/46298 (22%)]\tloss=66.0777\n",
      "Train Epoch: 8 [10880/46298 (23%)]\tloss=71.7614\n",
      "Train Epoch: 8 [11520/46298 (25%)]\tloss=54.5027\n",
      "Train Epoch: 8 [12160/46298 (26%)]\tloss=64.6918\n",
      "Train Epoch: 8 [12800/46298 (28%)]\tloss=64.5634\n",
      "Train Epoch: 8 [13440/46298 (29%)]\tloss=69.2282\n",
      "Train Epoch: 8 [14080/46298 (30%)]\tloss=91.0990\n",
      "Train Epoch: 8 [14720/46298 (32%)]\tloss=51.7614\n",
      "Train Epoch: 8 [15360/46298 (33%)]\tloss=63.2594\n",
      "Train Epoch: 8 [16000/46298 (35%)]\tloss=76.0357\n",
      "Train Epoch: 8 [16640/46298 (36%)]\tloss=59.4502\n",
      "Train Epoch: 8 [17280/46298 (37%)]\tloss=64.5622\n",
      "Train Epoch: 8 [17920/46298 (39%)]\tloss=53.2970\n",
      "Train Epoch: 8 [18560/46298 (40%)]\tloss=73.2650\n",
      "Train Epoch: 8 [19200/46298 (41%)]\tloss=60.7875\n",
      "Train Epoch: 8 [19840/46298 (43%)]\tloss=69.4930\n",
      "Train Epoch: 8 [20480/46298 (44%)]\tloss=86.6091\n",
      "Train Epoch: 8 [21120/46298 (46%)]\tloss=86.5997\n",
      "Train Epoch: 8 [21760/46298 (47%)]\tloss=86.8947\n",
      "Train Epoch: 8 [22400/46298 (48%)]\tloss=68.6583\n",
      "Train Epoch: 8 [23040/46298 (50%)]\tloss=77.5152\n",
      "Train Epoch: 8 [23680/46298 (51%)]\tloss=68.0730\n",
      "Train Epoch: 8 [24320/46298 (53%)]\tloss=72.7451\n",
      "Train Epoch: 8 [24960/46298 (54%)]\tloss=69.6865\n",
      "Train Epoch: 8 [25600/46298 (55%)]\tloss=65.9604\n",
      "Train Epoch: 8 [26240/46298 (57%)]\tloss=77.7695\n",
      "Train Epoch: 8 [26880/46298 (58%)]\tloss=91.8944\n",
      "Train Epoch: 8 [27520/46298 (59%)]\tloss=68.6884\n",
      "Train Epoch: 8 [28160/46298 (61%)]\tloss=50.5861\n",
      "Train Epoch: 8 [28800/46298 (62%)]\tloss=70.3742\n",
      "Train Epoch: 8 [29440/46298 (64%)]\tloss=69.5770\n",
      "Train Epoch: 8 [30080/46298 (65%)]\tloss=83.8171\n",
      "Train Epoch: 8 [30720/46298 (66%)]\tloss=58.3212\n",
      "Train Epoch: 8 [31360/46298 (68%)]\tloss=57.9385\n",
      "Train Epoch: 8 [32000/46298 (69%)]\tloss=71.2089\n",
      "Train Epoch: 8 [32640/46298 (70%)]\tloss=79.6051\n",
      "Train Epoch: 8 [33280/46298 (72%)]\tloss=78.3288\n",
      "Train Epoch: 8 [33920/46298 (73%)]\tloss=88.4164\n",
      "Train Epoch: 8 [34560/46298 (75%)]\tloss=64.0505\n",
      "Train Epoch: 8 [35200/46298 (76%)]\tloss=57.1161\n",
      "Train Epoch: 8 [35840/46298 (77%)]\tloss=75.1875\n",
      "Train Epoch: 8 [36480/46298 (79%)]\tloss=63.3426\n",
      "Train Epoch: 8 [37120/46298 (80%)]\tloss=87.2805\n",
      "Train Epoch: 8 [37760/46298 (82%)]\tloss=58.7925\n",
      "Train Epoch: 8 [38400/46298 (83%)]\tloss=83.4191\n",
      "Train Epoch: 8 [39040/46298 (84%)]\tloss=67.2519\n",
      "Train Epoch: 8 [39680/46298 (86%)]\tloss=74.3542\n",
      "Train Epoch: 8 [40320/46298 (87%)]\tloss=67.1089\n",
      "Train Epoch: 8 [40960/46298 (88%)]\tloss=60.4716\n",
      "Train Epoch: 8 [41600/46298 (90%)]\tloss=82.0663\n",
      "Train Epoch: 8 [42240/46298 (91%)]\tloss=72.6612\n",
      "Train Epoch: 8 [42880/46298 (93%)]\tloss=58.4205\n",
      "Train Epoch: 8 [43520/46298 (94%)]\tloss=71.9778\n",
      "Train Epoch: 8 [44160/46298 (95%)]\tloss=84.2195\n",
      "Train Epoch: 8 [44800/46298 (97%)]\tloss=59.6063\n",
      "Train Epoch: 8 [45440/46298 (98%)]\tloss=76.3774\n",
      "Train Epoch: 8 [46080/46298 (100%)]\tloss=77.4237\n",
      "Train Epoch: 9 [0/46298 (0%)]\tloss=73.9991\n",
      "Train Epoch: 9 [640/46298 (1%)]\tloss=52.5246\n",
      "Train Epoch: 9 [1280/46298 (3%)]\tloss=60.6434\n",
      "Train Epoch: 9 [1920/46298 (4%)]\tloss=52.4074\n",
      "Train Epoch: 9 [2560/46298 (6%)]\tloss=42.6144\n",
      "Train Epoch: 9 [3200/46298 (7%)]\tloss=50.2544\n",
      "Train Epoch: 9 [3840/46298 (8%)]\tloss=50.5838\n",
      "Train Epoch: 9 [4480/46298 (10%)]\tloss=51.6414\n",
      "Train Epoch: 9 [5120/46298 (11%)]\tloss=56.9174\n",
      "Train Epoch: 9 [5760/46298 (12%)]\tloss=58.5703\n",
      "Train Epoch: 9 [6400/46298 (14%)]\tloss=57.6176\n",
      "Train Epoch: 9 [7040/46298 (15%)]\tloss=54.6444\n",
      "Train Epoch: 9 [7680/46298 (17%)]\tloss=51.5396\n",
      "Train Epoch: 9 [8320/46298 (18%)]\tloss=55.6018\n",
      "Train Epoch: 9 [8960/46298 (19%)]\tloss=51.5530\n",
      "Train Epoch: 9 [9600/46298 (21%)]\tloss=54.0666\n",
      "Train Epoch: 9 [10240/46298 (22%)]\tloss=49.1266\n",
      "Train Epoch: 9 [10880/46298 (23%)]\tloss=57.4706\n",
      "Train Epoch: 9 [11520/46298 (25%)]\tloss=58.3960\n",
      "Train Epoch: 9 [12160/46298 (26%)]\tloss=65.1174\n",
      "Train Epoch: 9 [12800/46298 (28%)]\tloss=44.7929\n",
      "Train Epoch: 9 [13440/46298 (29%)]\tloss=68.2646\n",
      "Train Epoch: 9 [14080/46298 (30%)]\tloss=69.6261\n",
      "Train Epoch: 9 [14720/46298 (32%)]\tloss=59.7514\n",
      "Train Epoch: 9 [15360/46298 (33%)]\tloss=65.2720\n",
      "Train Epoch: 9 [16000/46298 (35%)]\tloss=48.3320\n",
      "Train Epoch: 9 [16640/46298 (36%)]\tloss=49.2954\n",
      "Train Epoch: 9 [17280/46298 (37%)]\tloss=52.7551\n",
      "Train Epoch: 9 [17920/46298 (39%)]\tloss=71.6174\n",
      "Train Epoch: 9 [18560/46298 (40%)]\tloss=53.9989\n",
      "Train Epoch: 9 [19200/46298 (41%)]\tloss=55.5927\n",
      "Train Epoch: 9 [19840/46298 (43%)]\tloss=52.8737\n",
      "Train Epoch: 9 [20480/46298 (44%)]\tloss=54.6669\n",
      "Train Epoch: 9 [21120/46298 (46%)]\tloss=74.8893\n",
      "Train Epoch: 9 [21760/46298 (47%)]\tloss=59.6250\n",
      "Train Epoch: 9 [22400/46298 (48%)]\tloss=62.5639\n",
      "Train Epoch: 9 [23040/46298 (50%)]\tloss=51.0466\n",
      "Train Epoch: 9 [23680/46298 (51%)]\tloss=59.4405\n",
      "Train Epoch: 9 [24320/46298 (53%)]\tloss=49.2787\n",
      "Train Epoch: 9 [24960/46298 (54%)]\tloss=53.4274\n",
      "Train Epoch: 9 [25600/46298 (55%)]\tloss=49.7436\n",
      "Train Epoch: 9 [26240/46298 (57%)]\tloss=58.2463\n",
      "Train Epoch: 9 [26880/46298 (58%)]\tloss=68.7234\n",
      "Train Epoch: 9 [27520/46298 (59%)]\tloss=67.8615\n",
      "Train Epoch: 9 [28160/46298 (61%)]\tloss=60.5858\n",
      "Train Epoch: 9 [28800/46298 (62%)]\tloss=71.8290\n",
      "Train Epoch: 9 [29440/46298 (64%)]\tloss=55.6328\n",
      "Train Epoch: 9 [30080/46298 (65%)]\tloss=77.8932\n",
      "Train Epoch: 9 [30720/46298 (66%)]\tloss=60.2799\n",
      "Train Epoch: 9 [31360/46298 (68%)]\tloss=59.8049\n",
      "Train Epoch: 9 [32000/46298 (69%)]\tloss=53.8711\n",
      "Train Epoch: 9 [32640/46298 (70%)]\tloss=54.4557\n",
      "Train Epoch: 9 [33280/46298 (72%)]\tloss=63.5273\n",
      "Train Epoch: 9 [33920/46298 (73%)]\tloss=64.0528\n",
      "Train Epoch: 9 [34560/46298 (75%)]\tloss=48.2378\n",
      "Train Epoch: 9 [35200/46298 (76%)]\tloss=67.1376\n",
      "Train Epoch: 9 [35840/46298 (77%)]\tloss=67.3778\n",
      "Train Epoch: 9 [36480/46298 (79%)]\tloss=69.1132\n",
      "Train Epoch: 9 [37120/46298 (80%)]\tloss=57.2380\n",
      "Train Epoch: 9 [37760/46298 (82%)]\tloss=59.0558\n",
      "Train Epoch: 9 [38400/46298 (83%)]\tloss=63.5678\n",
      "Train Epoch: 9 [39040/46298 (84%)]\tloss=52.0525\n",
      "Train Epoch: 9 [39680/46298 (86%)]\tloss=79.8165\n",
      "Train Epoch: 9 [40320/46298 (87%)]\tloss=63.3189\n",
      "Train Epoch: 9 [40960/46298 (88%)]\tloss=72.2363\n",
      "Train Epoch: 9 [41600/46298 (90%)]\tloss=68.8122\n",
      "Train Epoch: 9 [42240/46298 (91%)]\tloss=57.2289\n",
      "Train Epoch: 9 [42880/46298 (93%)]\tloss=66.9095\n",
      "Train Epoch: 9 [43520/46298 (94%)]\tloss=66.2692\n",
      "Train Epoch: 9 [44160/46298 (95%)]\tloss=82.8129\n",
      "Train Epoch: 9 [44800/46298 (97%)]\tloss=57.1947\n",
      "Train Epoch: 9 [45440/46298 (98%)]\tloss=50.0890\n",
      "Train Epoch: 9 [46080/46298 (100%)]\tloss=57.2339\n",
      "Train Epoch: 10 [0/46298 (0%)]\tloss=49.5741\n",
      "Train Epoch: 10 [640/46298 (1%)]\tloss=39.1821\n",
      "Train Epoch: 10 [1280/46298 (3%)]\tloss=50.8332\n",
      "Train Epoch: 10 [1920/46298 (4%)]\tloss=43.1431\n",
      "Train Epoch: 10 [2560/46298 (6%)]\tloss=50.7417\n",
      "Train Epoch: 10 [3200/46298 (7%)]\tloss=63.3537\n",
      "Train Epoch: 10 [3840/46298 (8%)]\tloss=34.5063\n",
      "Train Epoch: 10 [4480/46298 (10%)]\tloss=67.9602\n",
      "Train Epoch: 10 [5120/46298 (11%)]\tloss=47.6730\n",
      "Train Epoch: 10 [5760/46298 (12%)]\tloss=52.5941\n",
      "Train Epoch: 10 [6400/46298 (14%)]\tloss=47.6211\n",
      "Train Epoch: 10 [7040/46298 (15%)]\tloss=43.5819\n",
      "Train Epoch: 10 [7680/46298 (17%)]\tloss=39.1986\n",
      "Train Epoch: 10 [8320/46298 (18%)]\tloss=42.7679\n",
      "Train Epoch: 10 [8960/46298 (19%)]\tloss=46.7401\n",
      "Train Epoch: 10 [9600/46298 (21%)]\tloss=50.1470\n",
      "Train Epoch: 10 [10240/46298 (22%)]\tloss=43.2407\n",
      "Train Epoch: 10 [10880/46298 (23%)]\tloss=53.5367\n",
      "Train Epoch: 10 [11520/46298 (25%)]\tloss=53.8726\n",
      "Train Epoch: 10 [12160/46298 (26%)]\tloss=52.6061\n",
      "Train Epoch: 10 [12800/46298 (28%)]\tloss=47.9867\n",
      "Train Epoch: 10 [13440/46298 (29%)]\tloss=54.1399\n",
      "Train Epoch: 10 [14080/46298 (30%)]\tloss=53.0572\n",
      "Train Epoch: 10 [14720/46298 (32%)]\tloss=42.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [15360/46298 (33%)]\tloss=59.6572\n",
      "Train Epoch: 10 [16000/46298 (35%)]\tloss=44.6630\n",
      "Train Epoch: 10 [16640/46298 (36%)]\tloss=44.9073\n",
      "Train Epoch: 10 [17280/46298 (37%)]\tloss=45.2450\n",
      "Train Epoch: 10 [17920/46298 (39%)]\tloss=46.7452\n",
      "Train Epoch: 10 [18560/46298 (40%)]\tloss=62.0128\n",
      "Train Epoch: 10 [19200/46298 (41%)]\tloss=67.1607\n",
      "Train Epoch: 10 [19840/46298 (43%)]\tloss=48.9046\n",
      "Train Epoch: 10 [20480/46298 (44%)]\tloss=62.7464\n",
      "Train Epoch: 10 [21120/46298 (46%)]\tloss=45.4411\n",
      "Train Epoch: 10 [21760/46298 (47%)]\tloss=70.4469\n",
      "Train Epoch: 10 [22400/46298 (48%)]\tloss=47.2732\n",
      "Train Epoch: 10 [23040/46298 (50%)]\tloss=52.5769\n",
      "Train Epoch: 10 [23680/46298 (51%)]\tloss=44.1551\n",
      "Train Epoch: 10 [24320/46298 (53%)]\tloss=83.9287\n",
      "Train Epoch: 10 [24960/46298 (54%)]\tloss=56.1655\n",
      "Train Epoch: 10 [25600/46298 (55%)]\tloss=39.9976\n",
      "Train Epoch: 10 [26240/46298 (57%)]\tloss=54.3614\n",
      "Train Epoch: 10 [26880/46298 (58%)]\tloss=35.5917\n",
      "Train Epoch: 10 [27520/46298 (59%)]\tloss=53.8596\n",
      "Train Epoch: 10 [28160/46298 (61%)]\tloss=52.0282\n",
      "Train Epoch: 10 [28800/46298 (62%)]\tloss=62.7446\n",
      "Train Epoch: 10 [29440/46298 (64%)]\tloss=76.6192\n",
      "Train Epoch: 10 [30080/46298 (65%)]\tloss=54.8532\n",
      "Train Epoch: 10 [30720/46298 (66%)]\tloss=47.3970\n",
      "Train Epoch: 10 [31360/46298 (68%)]\tloss=56.1404\n",
      "Train Epoch: 10 [32000/46298 (69%)]\tloss=54.7138\n",
      "Train Epoch: 10 [32640/46298 (70%)]\tloss=43.8415\n",
      "Train Epoch: 10 [33280/46298 (72%)]\tloss=64.1924\n",
      "Train Epoch: 10 [33920/46298 (73%)]\tloss=55.3319\n",
      "Train Epoch: 10 [34560/46298 (75%)]\tloss=43.5030\n",
      "Train Epoch: 10 [35200/46298 (76%)]\tloss=55.1027\n",
      "Train Epoch: 10 [35840/46298 (77%)]\tloss=45.0328\n",
      "Train Epoch: 10 [36480/46298 (79%)]\tloss=54.0587\n",
      "Train Epoch: 10 [37120/46298 (80%)]\tloss=46.6638\n",
      "Train Epoch: 10 [37760/46298 (82%)]\tloss=48.3705\n",
      "Train Epoch: 10 [38400/46298 (83%)]\tloss=59.2985\n",
      "Train Epoch: 10 [39040/46298 (84%)]\tloss=68.0100\n",
      "Train Epoch: 10 [39680/46298 (86%)]\tloss=52.1997\n",
      "Train Epoch: 10 [40320/46298 (87%)]\tloss=53.7815\n",
      "Train Epoch: 10 [40960/46298 (88%)]\tloss=53.1988\n",
      "Train Epoch: 10 [41600/46298 (90%)]\tloss=62.3861\n",
      "Train Epoch: 10 [42240/46298 (91%)]\tloss=62.4246\n",
      "Train Epoch: 10 [42880/46298 (93%)]\tloss=48.5537\n",
      "Train Epoch: 10 [43520/46298 (94%)]\tloss=53.0852\n",
      "Train Epoch: 10 [44160/46298 (95%)]\tloss=67.6696\n",
      "Train Epoch: 10 [44800/46298 (97%)]\tloss=53.6620\n",
      "Train Epoch: 10 [45440/46298 (98%)]\tloss=45.9736\n",
      "Train Epoch: 10 [46080/46298 (100%)]\tloss=64.0539\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    #test(args, model, device, test_loader, epoch)\n",
    "    #adjust_lr(optimizer, epoch, args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bcf0d74-a504-45c2-8c04-91520af196f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"srcnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d432a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i506171\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386f5275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRCNN(\n",
       "  (layer1): Conv1d(1440, 1440, kernel_size=(1,), stride=(1,))\n",
       "  (layer2): Conv1d(1440, 2880, kernel_size=(1,), stride=(1,))\n",
       "  (fc1): Linear(in_features=2880, out_features=5760, bias=True)\n",
       "  (fc2): Linear(in_features=5760, out_features=1440, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449218be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
