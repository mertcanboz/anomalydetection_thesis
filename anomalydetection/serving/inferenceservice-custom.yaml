apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: {inferenceServiceName}
  namespace: {inferenceServiceNamespace}
  annotations:
    sidecar.istio.io/inject: "false"
spec:
  predictor:
    serviceAccountName: minio-sa
    containers:
      - name: kserve-container
        image: pytorch/torchserve:latest-cpu
        args:
          - torchserve
          - --start
          - --no-config-snapshots
          - --model-store=/mnt/models/model-store
          - --ts-config=/mnt/models/config/config.properties
          - --models all
        env:
          - name: STORAGE_URI
            value: {modelStorageUri}
